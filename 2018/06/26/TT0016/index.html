<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">

  <!-- PACE Progress Bar START -->
  
    <script src="/js/pace.min.js"></script>
    <link rel="stylesheet" href="https://github.com/HubSpot/pace/raw/master/themes/orange/pace-theme-flash.css">
  
  

  <!-- PACE Progress Bar START -->

  
  <title>机器学习算法精要 | TinTin</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  
  
  
  
  <meta name="description" content="原文来自：Essentials of Machine Learning Algorithms  广义而言，机器学习算法分三类1.监督学习工作原理：算法从一组给定的预测因子（独立变量）来预测目标/结果变量（或因变量），使用这些变量集生成映射输入到期望输出的函数，不断训练直到模型达到训练数据所需的精度水平。常见算法有：回归（Regression）、决策树（Decision Tree）、随机森林（Ran">
<meta property="og:type" content="article">
<meta property="og:title" content="机器学习算法精要">
<meta property="og:url" content="https://tintingo.github.io/2018/06/26/TT0016/index.html">
<meta property="og:site_name" content="TinTin">
<meta property="og:description" content="原文来自：Essentials of Machine Learning Algorithms  广义而言，机器学习算法分三类1.监督学习工作原理：算法从一组给定的预测因子（独立变量）来预测目标/结果变量（或因变量），使用这些变量集生成映射输入到期望输出的函数，不断训练直到模型达到训练数据所需的精度水平。常见算法有：回归（Regression）、决策树（Decision Tree）、随机森林（Ran">
<meta property="og:image" content="https://tintingo.github.io/images/T0016.jpg">
<meta property="og:updated_time" content="2018-06-27T03:27:01.997Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="机器学习算法精要">
<meta name="twitter:description" content="原文来自：Essentials of Machine Learning Algorithms  广义而言，机器学习算法分三类1.监督学习工作原理：算法从一组给定的预测因子（独立变量）来预测目标/结果变量（或因变量），使用这些变量集生成映射输入到期望输出的函数，不断训练直到模型达到训练数据所需的精度水平。常见算法有：回归（Regression）、决策树（Decision Tree）、随机森林（Ran">
<meta name="twitter:image" content="https://tintingo.github.io/images/T0016.jpg">
  
    <link rel="alternate" href="/atom.xml" title="TinTin" type="application/atom+xml">
  
  <link rel="icon" href="/css/images/favicon.ico">
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <link href="https://fonts.googleapis.com/css?family=Open+Sans|Montserrat:700" rel="stylesheet" type="text/css">
  <link href="https://fonts.googleapis.com/css?family=Roboto:400,300,300italic,400italic" rel="stylesheet" type="text/css">
  <link href="//cdn.bootcss.com/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet">
  <style type="text/css">
    @font-face{font-family:futura-pt;src:url(https://use.typekit.net/af/9749f0/00000000000000000001008f/27/l?subset_id=2&fvd=n5) format("woff2");font-weight:500;font-style:normal;}
    @font-face{font-family:futura-pt;src:url(https://use.typekit.net/af/90cf9f/000000000000000000010091/27/l?subset_id=2&fvd=n7) format("woff2");font-weight:500;font-style:normal;}
    @font-face{font-family:futura-pt;src:url(https://use.typekit.net/af/8a5494/000000000000000000013365/27/l?subset_id=2&fvd=n4) format("woff2");font-weight:lighter;font-style:normal;}
    @font-face{font-family:futura-pt;src:url(https://use.typekit.net/af/d337d8/000000000000000000010095/27/l?subset_id=2&fvd=i4) format("woff2");font-weight:400;font-style:italic;}</style>
    
  <link rel="stylesheet" id="athemes-headings-fonts-css" href="//fonts.googleapis.com/css?family=Yanone+Kaffeesatz%3A200%2C300%2C400%2C700&amp;ver=4.6.1" type="text/css" media="all">
  <link rel="stylesheet" href="/css/style.css">

  <script src="/js/jquery-3.1.1.min.js"></script>

  <!-- Bootstrap core CSS -->
  <link rel="stylesheet" href="/css/bootstrap.css" >
  <link rel="stylesheet" href="/css/hiero.css" >
  <link rel="stylesheet" href="/css/glyphs.css" >
  
    <link rel="stylesheet" href="/css/vdonate.css" >
  

  <!-- Custom CSS -->
  <link rel="stylesheet" href="/css/my.css">

</head>

<script>
var themeMenus = {};

  themeMenus["/"] = "首页"; 

  themeMenus["/archives"] = "归档"; 

  themeMenus["/life"] = "生活馆"; 

  themeMenus["/download"] = "下载"; 

  themeMenus["https://tintingo.github.io/images/about.html"] = "关于"; 

  themeMenus["/comments"] = "留言"; 

</script>


  <body data-spy="scroll" data-target="#toc" data-offset="50">


  <header id="allheader" class="site-header" role="banner">
  <div class="clearfix container">
      <div class="site-branding">

          <h1 class="site-title">
            
              <a href="/" title="TinTin" rel="home"> TinTin </a>
            
          </h1>

          
            <div class="site-description">学习matlab/python/HTML5/c/c++/机器学习/贝叶斯网络中~~~</div>
          
            
          <nav id="main-navigation" class="main-navigation" role="navigation">
            <a class="nav-open">Menu</a>
            <a class="nav-close">Close</a>
            <div class="clearfix sf-menu">

              <ul id="main-nav" class="nmenu sf-js-enabled">
                    
                      <li class="menu-item menu-item-type-custom menu-item-object-custom menu-item-home menu-item-1663"> <a class="" href="/">首页</a> </li>
                    
                      <li class="menu-item menu-item-type-custom menu-item-object-custom menu-item-home menu-item-1663"> <a class="" href="/archives">归档</a> </li>
                    
                      <li class="menu-item menu-item-type-custom menu-item-object-custom menu-item-home menu-item-1663"> <a class="" href="/life">生活馆</a> </li>
                    
                      <li class="menu-item menu-item-type-custom menu-item-object-custom menu-item-home menu-item-1663"> <a class="" href="/download">下载</a> </li>
                    
                      <li class="menu-item menu-item-type-custom menu-item-object-custom menu-item-home menu-item-1663"> <a class="" href="https://tintingo.github.io/images/about.html">关于</a> </li>
                    
                      <li class="menu-item menu-item-type-custom menu-item-object-custom menu-item-home menu-item-1663"> <a class="" href="/comments">留言</a> </li>
                    
              </ul>
            </div>
          </nav>


      </div>
  </div>
</header>


  <div id="originBgDiv" style="background: #fff; width: 100%;">

      <div style="max-height:600px; overflow: hidden;  display: flex; display: -webkit-flex; align-items: center;">
        <img id="originBg" width="100%" alt="" src="">
      </div>

  </div>

  <script>
  function setAboutIMG(){
      var imgUrls = "css/images/pose1.jpg,css/images/pose2.jpg,css/images/pose3.jpg".split(",");
      var random = Math.floor((Math.random() * imgUrls.length ));
      if (imgUrls[random].startsWith('http') || imgUrls[random].indexOf('://') >= 0) {
        document.getElementById("originBg").src=imgUrls[random];
      } else {
        document.getElementById("originBg").src='/' + imgUrls[random];
      }
  }
  bgDiv=document.getElementById("originBgDiv");
  if(location.pathname.match('about')){
    setAboutIMG();
    bgDiv.style.display='block';
  }else{
    bgDiv.style.display='none';
  }
  </script>



  <div id="container">
    <div id="wrap">
            
      <div id="content" class="outer">
        
          <section id="main" style="float:none;"><article id="post-TT0016" style="width: 66%; float:left;" class="article article-type-post" itemscope itemprop="blogPost" >
  <div id="articleInner" class="clearfix post-1016 post type-post status-publish format-standard has-post-thumbnail hentry category-template-2 category-uncategorized tag-codex tag-edge-case tag-featured-image tag-image tag-template">
    
<div class="article-gallery">
  <div class="article-gallery-photos">
    
      <a class="article-gallery-img fancybox" href="/images/T0016.jpg" rel="gallery_cjiwk78dd000m9keu8mwrop42">
        <img src="/images/T0016.jpg" itemprop="image">
      </a>
    
  </div>
</div>

    
      <header class="article-header">
        
  
    <h1 class="thumb" class="article-title" itemprop="name">
      机器学习算法精要
    </h1>
  

      </header>
    
    <div class="article-meta">
      
	Posted on <a href="/2018/06/26/TT0016/" class="article-date">
	  <time datetime="2018-06-26T02:43:28.189Z" itemprop="datePublished">June 26, 2018</time>
	</a>

      
	<span id="busuanzi_container_page_pv">
	  本文总阅读量<span id="busuanzi_value_page_pv"></span>次
	</span>

    </div>
    <div class="article-entry" itemprop="articleBody">
      
        <p><img src="/images/top.jpg" alt=""><br>原文来自：<a href="https://www.analyticsvidhya.com/blog/2017/09/common-machine-learning-algorithms/" target="_blank" rel="external">Essentials of Machine Learning Algorithms </a></p>
<h1 id="广义而言，机器学习算法分三类"><a href="#广义而言，机器学习算法分三类" class="headerlink" title="广义而言，机器学习算法分三类"></a>广义而言，机器学习算法分三类</h1><h2 id="1-监督学习"><a href="#1-监督学习" class="headerlink" title="1.监督学习"></a>1.监督学习</h2><p>工作原理：算法从一组给定的预测因子（独立变量）来预测目标/结果变量（或因变量），使用这些变量集生成映射输入到期望输出的函数，不断训练直到模型达到训练数据所需的精度水平。常见算法有：回归（Regression）、决策树（Decision Tree）、随机森林（Random Forest）、KNN、逻辑回归（Logistic Regression）等。</p>
<h2 id="2-无监督学习"><a href="#2-无监督学习" class="headerlink" title="2.无监督学习"></a>2.无监督学习</h2><p>工作原理：算法中没有任何目标或结果变量要预测/估计，而是用于不同群体的种群聚集，广泛应用于不同群体的细分。常见算法有：关联规则算法（Apriori algorithm）、K-means。</p>
<h2 id="3-增强学习"><a href="#3-增强学习" class="headerlink" title="3.增强学习"></a>3.增强学习</h2><p>工作原理：算法中，机器被训练来做出特定的决定，通过反复试验不断训练机器，机器从过去的经验中学习，捕捉最好的知识以做出准确的决策。常见算法有：马尔科夫决策过程(Markov Decision Process)。<br><a id="more"></a></p>
<h1 id="常用机器学习算法"><a href="#常用机器学习算法" class="headerlink" title="常用机器学习算法"></a>常用机器学习算法</h1><p>1.线性回归 - Linear Regression<br>2.逻辑回归 - Logistic Regression<br>3.决策树 - Decision Tree<br>4.支持向量机 - SVM<br>5.朴素贝叶斯 - Naive Bayes<br>6.邻近算法 - kNN<br>7.K均值 - K-Means<br>8.随机森林 - Random Forest<br>9.降维算法 - Dimensionality Reduction Algorithms<br>10.梯度提升算法 - Gradient Boosting algorithms （GBM、XGBoost、LightGBM、CatBoost）</p>
<h1 id="线性回归（Linear-Regression）"><a href="#线性回归（Linear-Regression）" class="headerlink" title="线性回归（Linear Regression）"></a>线性回归（Linear Regression）</h1><p>线性回归是用连续变量来估计实际值（房屋成本、通话次数、总销售额等）,通过拟合一条最佳的线来建立自变量和因变量之间的关系，这个最佳拟合线称为回归线，用线性方程y = a*x + b表示。<br>了解线性回归的最好方法是重温童年的经历。要求一个第五年级的孩子通过体重的递增顺序来给他班上的学生排队，在不给出他们的体重的情况下，你认为这个孩子会怎么做？他（她）可能会观察他们的身高和身材（视觉分析），并综合这些可见参数给他们排队。这就是现实生活中的线性回归！这个孩子实际上已经知道身高和身材与体重的关系是由一种像上面的等式关系决定的。<br>等式中，y为因变量，x为自变量，a为斜率，b为截距。系数a和b可通过极小化数据点与回归线之间的距离的平方差之和获得。<br>如下例中，已经确定了线性方程y = 0.2811x + 13.9为最佳拟合线，用这个方程式，通过体重，就可知道一个人的身高。<br><img src="/images/JQXX001.png" alt=""><br>线性回归主要有两类：简单线性回归和多元线性回归。简单线性回归的特点是一个自变量，多元线性回归的特征是多个（1个以上）自变量。在寻找最佳拟合线时，可以拟合多项式或曲线回归，这被称为多项式或曲线回归。<br>python代码<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#Import Library</span></div><div class="line"><span class="comment">#Import other necessary libraries like pandas, numpy...</span></div><div class="line">from sklearn import linear_model</div><div class="line"><span class="comment">#Load Train and Test datasets</span></div><div class="line"><span class="comment">#Identify feature and response variable(s) and values must be numeric and numpy arrays</span></div><div class="line">x_train=input_variables_values_training_datasets</div><div class="line">y_train=target_variables_values_training_datasets</div><div class="line">x_test=input_variables_values_test_datasets</div><div class="line"><span class="comment"># Create linear regression object</span></div><div class="line">linear = linear_model.LinearRegression()</div><div class="line"><span class="comment"># Train the model using the training sets and check score</span></div><div class="line">linear.fit(x_train, y_train)</div><div class="line">linear.score(x_train, y_train)</div><div class="line"><span class="comment">#Equation coefficient and Intercept</span></div><div class="line"><span class="built_in">print</span>(<span class="string">'Coefficient: \n'</span>, linear.coef_)</div><div class="line"><span class="built_in">print</span>(<span class="string">'Intercept: \n'</span>, linear.intercept_)</div><div class="line"><span class="comment">#Predict Output</span></div><div class="line">predicted= linear.predict(x_test)</div></pre></td></tr></table></figure></p>
<p>R代码<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#Load Train and Test datasets</span></div><div class="line"><span class="comment">#Identify feature and response variable(s) and values must be numeric and numpy arrays</span></div><div class="line">x_train &lt;- input_variables_values_training_datasets</div><div class="line">y_train &lt;- target_variables_values_training_datasets</div><div class="line">x_test &lt;- input_variables_values_test_datasets</div><div class="line">x &lt;- cbind(x_train,y_train)</div><div class="line"><span class="comment"># Train the model using the training sets and check score</span></div><div class="line">linear &lt;- lm(y_train ~ ., data = x)</div><div class="line">summary(linear)</div><div class="line"><span class="comment">#Predict Output</span></div><div class="line">predicted= predict(linear,x_test)</div></pre></td></tr></table></figure></p>
<h1 id="逻辑回归（Logistic-Regression）"><a href="#逻辑回归（Logistic-Regression）" class="headerlink" title="逻辑回归（Logistic Regression）"></a>逻辑回归（Logistic Regression）</h1><p>不要被它的名字混淆！它是一种分类而不是回归算法。它是用来估计基于给定自变量集的离散值（二进制值，如0/1，是/否，真/假）。简单地说，它通过将数据拟合到对数函数来预测事件发生的概率，因此，它也被称为对数回归。由于它预测了概率，其输出值介于0和1之间。<br>再一次通过一个简单的例子来理解一下。<br>假设你的朋友给你一个难题来解决，只有2种结果：解决、没解决。现在想象一下，机器通过给你做各种各样的测试来试图了解你擅长的科目，学习的结果将是这样的：如果给你一个十年级的三重测量问题，你有70%的概率来解决这个问题。另一方面，如果是五年级的历史问题，你只有30%的概率来解决这个问题。<br>在数学中，结果的对数几率（log odds：对数几率odds是体现阳性和阴性差异的这么一个指标）被模拟成预测变量的线性组合。<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">odds = p/ (1-p)          【事件发生可能性 / 事件发生可能性】</div><div class="line">ln(odds) = ln(p/(1-p))</div><div class="line">logit(p) = ln(p/(1-p)) = b0 + b1X1 + b2X2 + b3X3 + ... + bkXk</div></pre></td></tr></table></figure></p>
<p>如上，P是存在目标特征的概率，它选择观察样本值的最大似然参数，而不选择普通回归中最小平方误差和。<br>现在，你可能会问，为什么要选择log函数？为了简单起见，只能说这是复制阶跃函数最好的数学方法之一。<br><img src="/images/JQXX002.png" alt=""><br>Python代码<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#Import Library</span></div><div class="line">from sklearn.linear_model import LogisticRegression</div><div class="line"><span class="comment">#Assumed you have, X (predictor) and Y (target) for training data set and x_test(predictor) of test_dataset</span></div><div class="line"><span class="comment"># Create logistic regression object</span></div><div class="line">model = LogisticRegression()</div><div class="line"><span class="comment"># Train the model using the training sets and check score</span></div><div class="line">model.fit(X, y)</div><div class="line">model.score(X, y)</div><div class="line"><span class="comment">#Equation coefficient and Intercept</span></div><div class="line"><span class="built_in">print</span>(<span class="string">'Coefficient: \n'</span>, model.coef_)</div><div class="line"><span class="built_in">print</span>(<span class="string">'Intercept: \n'</span>, model.intercept_)</div><div class="line"><span class="comment">#Predict Output</span></div><div class="line">predicted= model.predict(x_test)</div></pre></td></tr></table></figure></p>
<p>R代码<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">x &lt;- cbind(x_train,y_train)</div><div class="line"><span class="comment"># Train the model using the training sets and check score</span></div><div class="line">logistic &lt;- glm(y_train ~ ., data = x,family=<span class="string">'binomial'</span>)</div><div class="line">summary(logistic)</div><div class="line"><span class="comment">#Predict Output</span></div><div class="line">predicted= predict(logistic,x_test)</div></pre></td></tr></table></figure></p>
<p>除此之外，为了改进模型，还可以尝试更多不同的步骤：包括交互项、去除特征、正则化技术、使用非线性模型。</p>
<h1 id="决策树（Decision-Tree）"><a href="#决策树（Decision-Tree）" class="headerlink" title="决策树（Decision Tree）"></a>决策树（Decision Tree）</h1><p>决策树是一种主要用于分类问题的监督学习算法，它适用于分类和连续因变量。在该算法中，我们将种群分成两个或更多的同质集，采用关键属性/自变量来尽可能区分的不同组。<br><img src="/images/JQXX003.png" alt=""><br>在上图中，你可以看到，基于多个属性，种群被划分为四个不同的组，以确定“他们是否会玩”，采用Gini、信息增益、Chi平方、熵等多种技术将种群划分为不同的异质集。<br>了解决策树是如何运作的最好方法是玩Jezzball——一个经典的微软游戏（下图）。本质上，你有一个带有可移动墙的房间，你需要创建墙壁能够清除最大的没有球的区域。<br><img src="/images/JQXX004.png" alt=""><br>所以，每次你用墙分开房间时，你试图在同一个房间里创造2个不同的群体。决策树方式工作非常相似，就是尽可能的将种群划分为不同的组。<br>Python代码<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#Import Library</span></div><div class="line"><span class="comment">#Import other necessary libraries like pandas, numpy...</span></div><div class="line">from sklearn import tree</div><div class="line"><span class="comment">#Assumed you have, X (predictor) and Y (target) for training data set and x_test(predictor) of test_dataset</span></div><div class="line"><span class="comment"># Create tree object </span></div><div class="line">model = tree.DecisionTreeClassifier(criterion=<span class="string">'gini'</span>) <span class="comment"># for classification, here you can change the algorithm as gini or entropy (information gain) by default it is gini  </span></div><div class="line"><span class="comment"># model = tree.DecisionTreeRegressor() for regression</span></div><div class="line"><span class="comment"># Train the model using the training sets and check score</span></div><div class="line">model.fit(X, y)</div><div class="line">model.score(X, y)</div><div class="line"><span class="comment">#Predict Output</span></div><div class="line">predicted= model.predict(x_test)</div></pre></td></tr></table></figure></p>
<p>R代码<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">library(rpart)</div><div class="line">x &lt;- cbind(x_train,y_train)</div><div class="line"><span class="comment"># grow tree </span></div><div class="line">fit &lt;- rpart(y_train ~ ., data = x,method=<span class="string">"class"</span>)</div><div class="line">summary(fit)</div><div class="line"><span class="comment">#Predict Output </span></div><div class="line">predicted= predict(fit,x_test)</div></pre></td></tr></table></figure></p>
<h1 id="SVM-Support-Vector-Machine"><a href="#SVM-Support-Vector-Machine" class="headerlink" title="SVM (Support Vector Machine)"></a>SVM (Support Vector Machine)</h1><p>SVM是一种分类方法。在该算法中，我们将每个数据项绘制为n维空间中的一个点（其中n是具有的特征数），其中每个特征的值是特定坐标的值。<br>例如，若我们只有两个特征，身高和头发长度，我们首先在二维空间中绘制这两个变量，其中每个点有两个坐标（这些坐标被称为支持向量）。<br><img src="/images/JQXX005.png" alt=""><br>现在，我们将找到一条分割两个不同分类数据集之间的数据的线，这是一条直线，使得两组中最靠近的点的距离最远。<br><img src="/images/JQXX006.png" alt=""><br>在上面的例子中，将数据分割成两个不同的类的线是黑线，因为这两个最靠近的点离直线最远，这条线就是我们的分类器。这样，看测试数据落在该线的哪一边，就可将新数据分为什么类。<br>Python代码<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#Import Library</span></div><div class="line">from sklearn import svm</div><div class="line"><span class="comment">#Assumed you have, X (predictor) and Y (target) for training data set and x_test(predictor) of test_dataset</span></div><div class="line"><span class="comment"># Create SVM classification object </span></div><div class="line">model = svm.svc() <span class="comment"># there is various option associated with it, this is simple for classification. You can refer link, for mo# re detail.</span></div><div class="line"><span class="comment"># Train the model using the training sets and check score</span></div><div class="line">model.fit(X, y)</div><div class="line">model.score(X, y)</div><div class="line"><span class="comment">#Predict Output</span></div><div class="line">predicted= model.predict(x_test)</div></pre></td></tr></table></figure></p>
<p>R代码<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">library(e1071)</div><div class="line">x &lt;- cbind(x_train,y_train)</div><div class="line"><span class="comment"># Fitting model</span></div><div class="line">fit &lt;-svm(y_train ~ ., data = x)</div><div class="line">summary(fit)</div><div class="line"><span class="comment">#Predict Output </span></div><div class="line">predicted= predict(fit,x_test)</div></pre></td></tr></table></figure></p>
<h1 id="朴素贝叶斯"><a href="#朴素贝叶斯" class="headerlink" title="朴素贝叶斯"></a>朴素贝叶斯</h1><p>朴素贝叶斯是一种基于贝叶斯定理的分类技术，具有预测属性之间的独立性假设。简单地说，朴素贝叶斯分类器假定类中的特定特征的存在与任何其他特征的存在无关。例如，如果一个水果是红色的、圆的、直径约3英寸的，它可以被认为是一个苹果。即使这些特征彼此依赖或存在其他特征，朴素贝叶斯分类器也认为所有这些属性对“这种水果是苹果”贡献的概率是独立的。<br>朴素贝叶斯模型易于建立，特别适用于非常大的数据集。由于它简单，朴素贝叶斯甚至被认为优于其他高度复杂的分类方法。<br>贝叶斯定理为通过P(C)、P(X)和P(X|C)来计算后验概率p(C|x)提供了一种途径。请看下面的方程式：<br><img src="/images/JQXX007.png" alt=""><br>其中，P(C|x)是给定（待测）属性的类（目标）的后验概率,P(C)是类的先验概率,P(x|c)是给定类情况下待测属性出现的概率,P(x)是待测属性的先验概率。<br>例：有一个包含天气和相应的目标变量“玩”的训练数据集，现在，我们需要根据天气情况来判断是否可以去玩。<br>按如下步骤执行：<br>第1步：将数据集转换为频率表<br>第2步：通过比如阴天的概率为0.29和去玩的概率为0.64来创建似然表。<br><img src="/images/JQXX008.png" alt=""><br>第3步：使用朴素贝叶斯公式计算每个类的后验概率，具有最高后验概率的类就是预测结果。<br>问题：如果天气晴朗会去玩，这个说法正确吗？<br>我们可以用上面讨论的方法求解它，P(Yes | Sunny) = P( Sunny | Yes) <em> P(Yes) / P (Sunny)<br>表中可知：P (Sunny |Yes) = 3/9 = 0.33, P(Sunny) = 5/14 = 0.36, P(Yes)= 9/14 = 0.64<br>那么，P (Yes | Sunny) = 0.33 </em> 0.64 / 0.36 = 0.60，具有较高的概率。<br>朴素贝叶斯使用类似的方法来预测各属性的不同类别的概率，该算法主要用于文本分类和多分类问题。<br>Python代码<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#Import Library</span></div><div class="line">from sklearn.naive_bayes import GaussianNB</div><div class="line"><span class="comment">#Assumed you have, X (predictor) and Y (target) for training data set and x_test(predictor) of test_dataset</span></div><div class="line"><span class="comment"># Create SVM classification object model = GaussianNB() # there is other distribution for multinomial classes like Bernoulli Naive Bayes, Refer link</span></div><div class="line"><span class="comment"># Train the model using the training sets and check score</span></div><div class="line">model.fit(X, y)</div><div class="line"><span class="comment">#Predict Output</span></div><div class="line">predicted= model.predict(x_test)</div></pre></td></tr></table></figure></p>
<p>R代码<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">library(e1071)</div><div class="line">x &lt;- cbind(x_train,y_train)</div><div class="line"><span class="comment"># Fitting model</span></div><div class="line">fit &lt;-naiveBayes(y_train ~ ., data = x)</div><div class="line">summary(fit)</div><div class="line"><span class="comment">#Predict Output </span></div><div class="line">predicted= predict(fit,x_test)</div></pre></td></tr></table></figure></p>
<h1 id="kNN-k-Nearest-Neighbors"><a href="#kNN-k-Nearest-Neighbors" class="headerlink" title="kNN (k- Nearest Neighbors)"></a>kNN (k- Nearest Neighbors)</h1><p>KNN可以用于分类和回归问题，而在工业上常用在分类问题上。K近邻算法是一种简单的算法，它存储了所有可用的样本，并通过其k领域的多数表决对新的样本进行分类。样本的分类是K近邻范围内所有点通过距离函数测量的多数共识。<br>这些距离函数可以是欧几里得（Euclidean）、曼哈顿（Manhattan）、闵可夫斯基（Minkowski）和汉明（Hamming）距离，前三个函数用于连续函数，第四个（Hamming）用于分类变量，如果k＝1，则将该情况简单地分给其最近邻的类。在进行KNN建模时，选择K值是最大的难点。<br><img src="/images/JQXX009.png" alt=""><br>KNN可以很容易地映射到我们的真实生活中，如果你想了解一个人，你没有他/她的信息，你可能从他的亲密朋友和他的圈子获得他/她的信息。<br>选择KNN之前要考虑的事项：1.KNN运行较耗时；2.变量需归一化，否则较高的范围变量会对它产生偏差；3.在KNN之前需进行如离群点、去噪的预处理工作。<br>Python代码<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#Import Library</span></div><div class="line">from sklearn.neighbors import KNeighborsClassifier</div><div class="line"><span class="comment">#Assumed you have, X (predictor) and Y (target) for training data set and x_test(predictor) of test_dataset</span></div><div class="line"><span class="comment"># Create KNeighbors classifier object model </span></div><div class="line">KNeighborsClassifier(n_neighbors=6) <span class="comment"># default value for n_neighbors is 5</span></div><div class="line"><span class="comment"># Train the model using the training sets and check score</span></div><div class="line">model.fit(X, y)</div><div class="line"><span class="comment">#Predict Output</span></div><div class="line">predicted= model.predict(x_test)</div></pre></td></tr></table></figure></p>
<p>R代码<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">library(knn)</div><div class="line">x &lt;- cbind(x_train,y_train)</div><div class="line"><span class="comment"># Fitting model</span></div><div class="line">fit &lt;-knn(y_train ~ ., data = x,k=5)</div><div class="line">summary(fit)</div><div class="line"><span class="comment">#Predict Output </span></div><div class="line">predicted= predict(fit,x_test)</div></pre></td></tr></table></figure></p>
<p><img src="/images/JQXX010.png" alt=""><br><img src="/images/JQXX011.png" alt=""></p>
<p><img src="/images/bottom.jpg" alt=""></p>

      
    </div>
    <footer class="entry-meta entry-footer">
      
      
      
        <div id="donation_div"></div>

<script src="/js/vdonate.js"></script>
<script>
var a = new Donate({
  title: '请随意打赏。您的支持将鼓励我继续创作!', // 可选参数，打赏标题
  btnText: '打赏支持', // 可选参数，打赏按钮文字
  el: document.getElementById('donation_div'),
  wechatImage: '/css/images/wechatpay.jpg',
  alipayImage: '/css/images/alipay.jpg'
});
</script>
      
            
      
	  
        
	<div id="comment">
		<!-- 来必力City版安装代码 -->
		<div id="lv-container" data-id="city" data-uid="MTAyMC8zMjU1NS85MTE2">
		<script type="text/javascript">
		   (function(d, s) {
		       var j, e = d.getElementsByTagName(s)[0];

		       if (typeof LivereTower === 'function') { return; }

		       j = d.createElement(s);
		       j.src = 'https://cdn-city.livere.com/js/embed.dist.js';
		       j.async = true;

		       e.parentNode.insertBefore(j, e);
		   })(document, 'script');
		</script>
		<noscript>为正常使用来必力评论功能请激活JavaScript</noscript>
		</div>
		<!-- City版安装代码已完成 -->
	</div>


      
    </footer>
  </div>
  
    
<nav id="article-nav">
  
  
    <a href="/2018/06/11/TT0015/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">下一篇</strong>
      <div class="article-nav-title">大学发明专利申请</div>
    </a>
  
</nav>

  
</article>

<!-- Table of Contents -->

  <aside id="sidebar">
    <div id="toc" class="toc-article">
    <strong class="toc-title">文章目录</strong>
    
      <ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#广义而言，机器学习算法分三类"><span class="nav-number">1.</span> <span class="nav-text">广义而言，机器学习算法分三类</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#1-监督学习"><span class="nav-number">1.1.</span> <span class="nav-text">1.监督学习</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-无监督学习"><span class="nav-number">1.2.</span> <span class="nav-text">2.无监督学习</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3-增强学习"><span class="nav-number">1.3.</span> <span class="nav-text">3.增强学习</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#常用机器学习算法"><span class="nav-number">2.</span> <span class="nav-text">常用机器学习算法</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#线性回归（Linear-Regression）"><span class="nav-number">3.</span> <span class="nav-text">线性回归（Linear Regression）</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#逻辑回归（Logistic-Regression）"><span class="nav-number">4.</span> <span class="nav-text">逻辑回归（Logistic Regression）</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#决策树（Decision-Tree）"><span class="nav-number">5.</span> <span class="nav-text">决策树（Decision Tree）</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#SVM-Support-Vector-Machine"><span class="nav-number">6.</span> <span class="nav-text">SVM (Support Vector Machine)</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#朴素贝叶斯"><span class="nav-number">7.</span> <span class="nav-text">朴素贝叶斯</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#kNN-k-Nearest-Neighbors"><span class="nav-number">8.</span> <span class="nav-text">kNN (k- Nearest Neighbors)</span></a></li></ol>
    
    </div>
  </aside>
</section>
        
      </div>
      <footer id="footer" class="site-footer">
  

  <div class="clearfix container">
      <div class="site-info">
	      &copy; 2018 TinTin All Rights Reserved.
          
            <span id="busuanzi_container_site_uv">
              本站访客数<span id="busuanzi_value_site_uv"></span>人次  
              本站总访问量<span id="busuanzi_value_site_pv"></span>次
            </span>
          
      </div>
      <div class="site-credit">
        主题： <a href="https://github.com/iTimeTraveler/hexo-theme-hiero" target="_blank">hiero</a>
      </div>
  </div>
</footer>


<!-- min height -->

<script>
    var contentdiv = document.getElementById("content");

    contentdiv.style.minHeight = document.body.offsetHeight - document.getElementById("allheader").offsetHeight - document.getElementById("footer").offsetHeight + "px";
</script>

<!-- Custome JS -->
<script src="/js/my.js"></script>
    </div>
    <!-- <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
    <a href="/life" class="mobile-nav-link">life</a>
  
    <a href="/download" class="mobile-nav-link">download</a>
  
    <a href="https://tintingo.github.io/images/about.html" class="mobile-nav-link">About</a>
  
    <a href="/comments" class="mobile-nav-link">comment</a>
  
</nav> -->
    

<!-- mathjax config similar to math.stackexchange -->

<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      processEscapes: true
    }
  });
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
      }
    });
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for(i=0; i < all.length; i += 1) {
            all[i].SourceElement().parentNode.className += ' has-jax';
        }
    });
</script>

<script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/scripts.js"></script>
<script src="/js/bootstrap.js"></script>
<script src="/js/main.js"></script>







  <div style="display: none;">
    <script src="https://s95.cnzz.com/z_stat.php?id=1271468861&web_id=1271468861" language="JavaScript"></script>
  </div>



	<script async src="//dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js">
	</script>







  </div>

  <a id="rocket" href="#top" class=""></a>
  <script type="text/javascript" src="/js/totop.js" async=""></script>
</body>
</html>
